{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Story Score\n",
    "Story-Score is an example project that aims at automatically adding background scores to textual storylines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us consider the following example story line. This project showcases `huggingface transformer` models in conjunction with `beatoven.ai` to create a background score for the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storylines = [\n",
    "    \"Oh my god, that was so scary. The ghost of Colonel Sanders was eating at my local K F C.\",\n",
    "    \"As Rachel was looking around, everyone was in happy spirits as they were dancing.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install dependencies\n",
    "```\n",
    "pip install -r requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we utilize the microsoft speecht5 model to synthesis speech from out text above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "speech_synthesiser = pipeline(\"text-to-speech\", \"microsoft/speecht5_tts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import torch\n",
    "embeddings_dataset = load_dataset(\"Matthijs/cmu-arctic-xvectors\", split=\"validation\")\n",
    "speaker_embedding = torch.tensor(embeddings_dataset[7306][\"xvector\"]).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, we utilize a emotion detector model hosted on huggingface Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "text_emotion_detector = pipeline(task=\"text-classification\", model=\"SamLowe/roberta-base-go_emotions\", top_k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We utilize Beatoven.ai to create our background score, for this we need the [Beatoven Public SDK](https://github.com/Beatoven/public-api/tree/main/sdk) and an `API_KEY` as per the usage example in the [docs](https://github.com/Beatoven/public-api/tree/main/sdk#usage).\n",
    "\n",
    "```python\n",
    "os.environ[\"BEATOVEN_API_KEY\"] = \"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "from scipy.io import wavfile\n",
    "from beatoven_sdk import compose_new_track\n",
    "from utils import extract_emotion, download_track\n",
    "\n",
    "output_audio = AudioSegment.empty()\n",
    "count = 0\n",
    "for sentence in storylines:\n",
    "    count += 1\n",
    "    speech = speech_synthesiser(sentence, forward_params={\"speaker_embeddings\": speaker_embedding})\n",
    "    sampling_rate = speech[\"sampling_rate\"]\n",
    "    audio_data = speech[\"audio\"].squeeze()\n",
    "    duration = (len(audio_data)/sampling_rate)*1000\n",
    "    wavfile.write(\"audio/text_speech_\"+str(count)+\".wav\", rate=sampling_rate, data=audio_data)\n",
    "\n",
    "    mood = extract_emotion(text_emotion_detector(sentence)[0])\n",
    "    print(mood)\n",
    "    track_id, track_url = await compose_new_track(\n",
    "        title=\"my story lines \"+str(count),\n",
    "        track_duration=duration,\n",
    "        track_genre=\"cinematic\",\n",
    "        track_tempo=\"medium\",\n",
    "        mood=mood,\n",
    "    )\n",
    "    print(track_url)\n",
    "    await download_track(track_url,\"audio/composed_track_\"+str(count)+\".mp3\")\n",
    "\n",
    "    text_speech = AudioSegment.from_wav(\"./audio/text_speech_\"+str(count)+\".wav\")\n",
    "    background_score = AudioSegment.from_mp3(\"./audio/composed_track_\"+str(count)+\".mp3\")\n",
    "    background_score = background_score-6\n",
    "    output_audio = text_speech.overlay(background_score, position=0)\n",
    "    output_audio.export(\"audio/output_\"+str(count)+\".mp3\", format=\"mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "Audio(\"output.mp3\", rate=sampling_rate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
